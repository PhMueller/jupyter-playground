{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow CAVE + HpBandster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will present you a example workflow of how to efficiently optimize a algorithm using our frameworks \n",
    "<a href=\"https://github.com/automl/CAVE\" target=\"_blank\">CAVE</a> and <a href=\"https://github.com/automl/HpBandSter\" target=\"_blank\">HpBandSter</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short introduction to the used frameworks\n",
    "### CAVE\n",
    "\n",
    "Hier sollte eine kurze Beschreibung von Cave stehen.\n",
    "\n",
    "### HpBandSter\n",
    "\n",
    "Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. With HpBanster, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.\n",
    "\n",
    "For more insights, please consider the paper: <a href=\"https://arxiv.org/abs/1807.01774\" target=\"_blank\">BOHB: Robust and Efficient Hyperparameter Optimization at Scale</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we guide you through the following steps:\n",
    "#### 1) Given a algorithm to optimize and a *configuration space*, we will run BOHB on this problem. \n",
    "This step contains: \n",
    "+ Setting up a worker, which runs the given algorithmn with all the sampled configurations. Here it's a simple scipy implementation of a svm, training to classify the MNISTdataset.\n",
    "+ Setting up a nameserver, which organizes the possible multiple workers\n",
    "+ Starting the optimizer, here BOHB.\n",
    "\n",
    "\n",
    "This will return us the optimization run results. For example the best hyperparameter configuration, which is often referred to as *incumbent*. \n",
    "Also a lot of information like which configurations has been used, as well as their performances.\n",
    "#### 2) We will pass the BOHB results into the CAVE-tool.\n",
    "It will give insights into the \n",
    "+ Parameter importance, \n",
    "+ performance analysis,\n",
    "+ feature analysis and \n",
    "+ configuration behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neural_network, metrics\n",
    "from hpbandster.core.worker import Worker\n",
    "\n",
    "class MyWorker(Worker):\n",
    "    def __init__(self):\n",
    "        digits = datasets.load_digits()\n",
    "        n_samples = len(digits.images)\n",
    "        data = digits.images.reshape((n_samples, -1))\n",
    "        \n",
    "        self.train_x = data[:n_samples // 2]\n",
    "        self.train_y = digits.target[:n_samples // 2]\n",
    "        \n",
    "        self.test_x = data[n_samples // 2:]\n",
    "        self.test_y = digits.target[n_samples // 2:]\n",
    "\n",
    "    def compute(self, config, budget, *args, **kwargs):\n",
    "        clf = neural_network.MLPClassifier()\n",
    "        clf.fit(self.train_x, self.train_y)\n",
    "        \n",
    "        predicted = clf.predict(self.test_x)\n",
    "        print(clf.loss_)\n",
    "        accuracy = clf.score(self.test_x, self.test_y)\n",
    "\n",
    "        print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "              % (classifier, metrics.classification_report(self.test_y, predicted)))\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(self.test_y, predicted))\n",
    "\n",
    "        images_and_predictions = list(zip(self.test_x, predicted))\n",
    "        for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "            plt.subplot(2, 4, index + 5)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "            plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004791957977489443\n",
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.95      0.97        88\n",
      "          1       0.95      0.88      0.91        91\n",
      "          2       0.96      0.95      0.96        86\n",
      "          3       0.93      0.84      0.88        91\n",
      "          4       0.98      0.93      0.96        92\n",
      "          5       0.85      0.96      0.90        91\n",
      "          6       0.98      0.99      0.98        91\n",
      "          7       0.89      0.92      0.91        89\n",
      "          8       0.90      0.85      0.88        88\n",
      "          9       0.82      0.95      0.88        92\n",
      "\n",
      "avg / total       0.93      0.92      0.92       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[84  0  1  0  1  1  1  0  0  0]\n",
      " [ 0 80  0  0  0  0  0  0  2  9]\n",
      " [ 0  0 82  2  0  0  0  2  0  0]\n",
      " [ 0  0  1 76  0  6  0  4  4  0]\n",
      " [ 1  0  0  0 86  0  1  0  0  4]\n",
      " [ 0  0  0  0  0 87  0  0  2  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  2  1  1  0 82  0  3]\n",
      " [ 0  3  1  0  0  5  0  3 75  1]\n",
      " [ 0  0  0  2  0  2  0  1  0 87]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c7bd4f9c36de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyWorker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-67d94e173346>\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, config, budget, *args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction: %i'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    651\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    652\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 653\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    }
   ],
   "source": [
    "m = MyWorker()\n",
    "m.compute(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hpbandster.core.worker import Worker\n",
    "\n",
    "class MyWorker(Worker):\n",
    "    def compute(self, config, budget, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Simple example for a compute function\n",
    "        The loss is just a the config + some noise (that decreases with the budget)\n",
    "        There is a 10 percent failure probability for any run, just to demonstrate\n",
    "        the robustness of Hyperband agains these kinds of failures.\n",
    "\n",
    "        For dramatization, the function sleeps for one second, which emphasizes\n",
    "        the speed ups achievable with parallel workers.\n",
    "\n",
    "        Args:\n",
    "            config: dictionary containing the sampled configurations by the optimizer\n",
    "            budget: (float) amount of time/epochs/etc. the model can use to train\n",
    "\n",
    "        Returns:\n",
    "            dictionary with mandatory fields:\n",
    "                'loss' (scalar)\n",
    "                'info' (dict)\n",
    "        \"\"\"\n",
    "\n",
    "        # simulate some random failure\n",
    "        if random.random() < 0.:\n",
    "            raise RuntimeError(\"Random runtime error!\")\n",
    "\n",
    "        res = []\n",
    "        for i in range(int(budget)):\n",
    "            tmp = np.clip(config['x'] + np.random.randn()/budget, config['x']/2, 1.5*config['x'])\n",
    "            res.append(tmp)\n",
    "\n",
    "        return({\n",
    "                    'loss': np.abs(np.mean(res)),  # this is the a mandatory field to run hyperband\n",
    "                    'info': res  # can be used for any user-defined information - also mandatory\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "import ConfigSpace.read_and_write.json as json_writer\n",
    "import hpbandster.core.nameserver as hpns\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "from hpbandster.examples.commons import sample_configspace\n",
    "\n",
    "\n",
    "# First, create a ConfigSpace-Object.\n",
    "# It contains the hyperparameters to be optimized\n",
    "# For more details, please have a look in the ConfigSpace-Example in the Documentation\n",
    "config_space = sample_configspace()\n",
    "\n",
    "# Write the ConfigSpace for later use to file\n",
    "with open('example1_configspace.json', 'w') as fh:\n",
    "    fh.write(json_writer.write(config_space))\n",
    "v\n",
    "\n",
    "# Every run has to have a unique (at runtime) id.\n",
    "# This needs to be unique for concurrent runs, i.e. when multiple\n",
    "# instances run at the same time, they have to have different ids\n",
    "run_id = '0'\n",
    "\n",
    "\n",
    "# Step 1:\n",
    "# Every run needs a nameserver. It could be a 'static' server with a\n",
    "# permanent address, but here it will be started for the local machine with a random port.\n",
    "# The nameserver manages the concurrent running workers across all possible threads or clusternodes.\n",
    "NS = hpns.NameServer(  run_id=run_id,\n",
    "                       host='localhost',\n",
    "                       port=0,\n",
    "                    )\n",
    "ns_host, ns_port = NS.start()\n",
    "\n",
    "\n",
    "# Step 2:\n",
    "# The worker implements the connection to the model to be evaluated.\n",
    "# Its 'compute'-method will be called later by the BOHB-optimizer repeatedly\n",
    "# with the sampled configurations and return the computed loss (and additional infos).\n",
    "# Further usages of the worker will be covered in a later example.\n",
    "w = MyWorker(   nameserver=ns_host,\n",
    "                nameserver_port=ns_port,\n",
    "                run_id=run_id,  # unique Hyperband run id (same as nameserver's)\n",
    "            )\n",
    "w.run(background=True)\n",
    "\n",
    "\n",
    "# Step 3:\n",
    "# In the last of the 3 Steps, we create an optimizer object.\n",
    "# It samples configurations from the ConfigurationSpace, using succesive halfing.\n",
    "# The number of sampled configurations is determined by the\n",
    "# parameters eta, min_budget and max_budget.\n",
    "# After evaluating each configuration, starting with the minimum budget\n",
    "# on the same subset size, only a fraction of 1 / eta of them\n",
    "# 'advances' to the next round. At the same time the current budget will be doubled.\n",
    "# This process runs until the maximum budget is reached.\n",
    "bohb = BOHB(  configspace = config_space,\n",
    "              run_id = run_id,                       # same as nameserver's\n",
    "              eta=3, min_budget=27, max_budget=243,  # Hyperband parameters\n",
    "              nameserver=ns_host,\n",
    "              nameserver_port = ns_port,\n",
    "              ping_interval=3600,                    # how often master pings for workers (in seconds)\n",
    "           )\n",
    "\n",
    "# Then start the optimizer. The n_iterations parameter specifies\n",
    "# the number of iterations to be performed in this run\n",
    "res = bohb.run(n_iterations=2)\n",
    "\n",
    "# After the optimizer run, we shutdown the master.\n",
    "bohb.shutdown(shutdown_workers=True)\n",
    "\n",
    "\n",
    "# BOHB will return a result object.\n",
    "# It holds informations about the optimization run like the incumbent (=best) configuration.\n",
    "# For further details about the result-object, see its documentation.\n",
    "id2config = res.get_id2config_mapping()\n",
    "print('A total of %i unique configurations where sampled.' % len(id2config.keys()))\n",
    "print('A total of %i runs where executed.' % len(res.get_all_runs()))\n",
    "\n",
    "\n",
    "# The incumbent trajectory is a dictionary with all the configuration IDs, the times the runs\n",
    "# finished, their respective budgets, and corresponding losses.\n",
    "# It's used to do meaningful plots of the optimization process.\n",
    "incumbent_trajectory = res.get_incumbent_trajectory()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(incumbent_trajectory['times_finished'], incumbent_trajectory['losses'])\n",
    "plt.xlabel('wall clock time [s]')\n",
    "plt.ylabel('incumbent loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================\n",
      "Recognizing hand-written digits\n",
      "================================\n",
      "\n",
      "An example showing how the scikit-learn can be used to recognize images of\n",
      "hand-written digits.\n",
      "\n",
      "This example is commented in the\n",
      ":ref:`tutorial section of the user manual <introduction>`.\n",
      "\n",
      "\n",
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADuCAYAAAAZZe3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQDIENwAkQ3ADQDIENwAkQ3ADQDL/DzrIYESJPqAkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================\n",
    "Recognizing hand-written digits\n",
    "================================\n",
    "\n",
    "An example showing how the scikit-learn can be used to recognize images of\n",
    "hand-written digits.\n",
    "\n",
    "This example is commented in the\n",
    ":ref:`tutorial section of the user manual <introduction>`.\n",
    "\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "\n",
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
