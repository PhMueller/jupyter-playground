{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow CAVE + HpBandster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will present you a example workflow of how to efficiently optimize a algorithm using our frameworks \n",
    "<a href=\"https://github.com/automl/CAVE\" target=\"_blank\">CAVE</a> and <a href=\"https://github.com/automl/HpBandSter\" target=\"_blank\">HpBandSter</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short introduction to the used frameworks\n",
    "### CAVE\n",
    "\n",
    "Hier sollte eine kurze Beschreibung von Cave stehen.\n",
    "\n",
    "### HpBandSter\n",
    "\n",
    "Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. With HpBanster, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.\n",
    "\n",
    "For more insights, please consider the paper: <a href=\"https://arxiv.org/abs/1807.01774\" target=\"_blank\">BOHB: Robust and Efficient Hyperparameter Optimization at Scale</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we guide you through the following steps:\n",
    "#### 1) Given a algorithm to optimize and a *configuration space*, we will run BOHB on this problem. \n",
    "This step contains: \n",
    "1. Setting up a worker, which runs the given algorithmn with all the sampled configurations. Here it's a simple scipy implementation of a svm, training to classify the MNISTdataset.\n",
    "2. Defining a configurations space for the classifier using our <a href=\"https://github.com/automl/ConfigSpace\" target=\"_blank\">ConfigSpace module</a>.\n",
    "3. Setting up a nameserver, which organizes the possible multiple workers and starting the optimizer, here BOHB.\n",
    "\n",
    "\n",
    "This will return us the optimization run results. For example the best hyperparameter configuration, which is often referred to as *incumbent*. \n",
    "Also a lot of information like which configurations has been used, as well as their performances.\n",
    "#### 2) We will pass the BOHB results into the CAVE-tool.\n",
    "It will give insights into the \n",
    "1. Parameter importance, \n",
    "2. performance analysis,\n",
    "3. feature analysis and \n",
    "4. configuration behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Setting up a worker class\n",
    "+ inherit from the hpbandster.core.worker class\n",
    "+ load the mnist data in the init-method\n",
    "+ overwrite the compute methode: the training of the model happens here\n",
    "+ make sure that the returned dictionary contains the fields **loss** and **info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neural_network, metrics\n",
    "from hpbandster.core.worker import Worker\n",
    "\n",
    "class MyWorker(Worker):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyWorker, self).__init__(*args, **kwargs)\n",
    "        # We are loading the MNIST dataset and split it into a\n",
    "        # training and a test set.\n",
    "        digits = datasets.load_digits()\n",
    "        n_samples = len(digits.images)\n",
    "        data = digits.images.reshape((n_samples, -1))\n",
    "        \n",
    "        self.train_x = data[:n_samples // 2]\n",
    "        self.train_y = digits.target[:n_samples // 2]\n",
    "        self.test_x = data[n_samples // 2:]\n",
    "        self.test_y = digits.target[n_samples // 2:]\n",
    "\n",
    "    def compute(self, config, budget, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Simple example for a compute function. It'll be repeatedly called by the optimizer. \n",
    "        \n",
    "        Args:\n",
    "            config: dictionary containing the sampled configurations by the optimizer\n",
    "            budget: (float) amount of time/epochs/etc. the model can use to train\n",
    "\n",
    "        Returns:\n",
    "            dictionary with mandatory fields:\n",
    "                'loss' (scalar)\n",
    "                'info' (dict)\n",
    "        \"\"\"\n",
    "        beta_1 = 0  if 'beta_1' not in config else config['beta_1']\n",
    "        beta_2 = 0  if 'beta_2' not in config else config['beta_2']\n",
    "        \n",
    "        clf = neural_network.MLPClassifier(max_iter=int(budget),\n",
    "                                           learning_rate='constant',\n",
    "                                           learning_rate_init=config['learning_rate_init'],\n",
    "                                           activation=config['activation'],\n",
    "                                           solver=config['solver'],\n",
    "                                           beta_1=beta_1, \n",
    "                                           beta_2=beta_2\n",
    "                                          )\n",
    "        clf.fit(self.train_x, self.train_y)\n",
    "        \n",
    "        predicted = clf.predict(self.test_x)\n",
    "        loss_train = metrics.log_loss(self.train_y, clf.predict_proba(self.train_x))\n",
    "        loss_test = metrics.log_loss(self.test_y, clf.predict_proba(self.test_x))\n",
    "\n",
    "        accuracy_train = clf.score(self.train_x, self.train_y)\n",
    "        accuracy_test = clf.score(self.test_x, self.test_y)\n",
    "        \n",
    "        # print(clf.n_iter_)\n",
    "                \n",
    "        # print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "        #       % (classifier, metrics.classification_report(self.test_y, predicted)))\n",
    "        # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(self.test_y, predicted))\n",
    "        \n",
    "        return ({\n",
    "            'loss': loss_train,  # this is the a mandatory field to run hyperband\n",
    "            'info': {'loss_train': loss_train,\n",
    "                     'loss_test': loss_test,\n",
    "                     'accuracy_train': accuracy_train,\n",
    "                     'accuracy_test': accuracy_test,\n",
    "                     \n",
    "                    }  # can be used for any user-defined information - also mandatory\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) ConfigSpace:\n",
    "Now we define the configuration space with the hyperparameters we'd like to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ConfigSpace as CS\n",
    "import ConfigSpace.hyperparameters as CSH\n",
    "import ConfigSpace.read_and_write.json as json_writer\n",
    "\n",
    "def sample_configspace():\n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    config_space.add_hyperparameter(CSH.CategoricalHyperparameter('activation', ['tanh', 'relu']))\n",
    "    config_space.add_hyperparameter(CS.UniformFloatHyperparameter('learning_rate_init', lower=1e-6, upper=1e-2, log=True))\n",
    "    \n",
    "    solver = CSH.CategoricalHyperparameter('solver', ['sgd', 'adam'])\n",
    "    config_space.add_hyperparameter(solver)\n",
    "    \n",
    "    beta_1 = CS.UniformFloatHyperparameter('beta_1', lower=0, upper=1)\n",
    "    config_space.add_hyperparameter(beta_1)\n",
    "    \n",
    "    condition = CS.EqualsCondition(beta_1, solver, 'adam')\n",
    "    config_space.add_condition(condition)\n",
    "    \n",
    "    beta_2 = CS.UniformFloatHyperparameter('beta_2', lower=0, upper=1)\n",
    "    config_space.add_hyperparameter(beta_2)\n",
    "    \n",
    "    condition = CS.EqualsCondition(beta_2, solver, 'adam')\n",
    "    config_space.add_condition(condition)\n",
    "    \n",
    "    return config_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Setting up the HpBandSter Nameserver and starting the optimization run\n",
    "HpBandster supports parallel computation. To organize the workers, which can run on either a local machine or a cluster.  \n",
    "We import also the ConfigSpace-to-json-writer, to save the configuration space to file, which we will use later in CAVE.\n",
    "\n",
    "**NOTE:** Unfortunately, this step is *not done automatically* but is mandatory for the analysis with CAVE.  \n",
    "We recommend to save the configuration space every time you use BOHB.\n",
    "\n",
    "**Step 1:**  \n",
    "Every run needs a nameserver. It could be a 'static' server with a permanent address, but here it will be started for the local machine with a random port.  \n",
    "The nameserver manages the concurrent running workers across all possible threads or clusternodes.\n",
    "\n",
    "**Step 2:**  \n",
    "The worker implements the connection to the model to be evaluated. Its 'compute'-method will be called later by the BOHB-optimizer repeatedly with the sampled configurations and return the computed loss (and additional infos).\n",
    "\n",
    "**Step 3:**  \n",
    "In the last of the 3 Steps, we create an optimizer object.It samples configurations from the ConfigurationSpace, using succesive halving. The number of sampled configurations is determined by the parameters eta, min_budget and max_budget.  \n",
    "After evaluating each configuration, starting with the minimum budget on the same subset size, only a fraction of 1 / eta of them *advances* to the next round. At the same time the current budget will be doubled. This process runs until the maximum budget is reached.  \n",
    "And it will be repeated for *n_iterations* runs.\n",
    "\n",
    "**NOTE:** BOHB does not build a new model at the beginning of every SuccessiveHalving run. Instead it collects all evaluations on all budgets and uses the largest budget with enough evaluations as a base for future evaluations.  \n",
    "\n",
    "**Step 4:**  \n",
    "Bohb will return a result object, which can be used to get informations about the incumbent (=best configuration) or the incumbent trajectory.  \n",
    "The results will be stored, if not specified, to the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hpbandster:DISPATCHER: started the 'discover_worker' thread\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start listening for jobs\n",
      "INFO:hpbandster:DISPATCHER: started the 'job_runner' thread\n",
      "INFO:hpbandster:DISPATCHER: Pyro daemon running on localhost:56682\n",
      "INFO:hpbandster:DISPATCHER: discovered new worker, hpbandster.run_0.worker.DESKTOP-KV1H67P.787222276\n",
      "INFO:hpbandster:HBMASTER: adjusted queue size to (0, 1)\n",
      "INFO:hpbandster:DISPATCHER: A new worker triggered discover_worker\n",
      "INFO:hpbandster:HBMASTER: starting run at 1532612839.8922799\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 0)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 1)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 2)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 3)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 4)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 5)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 6)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 7)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 7) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 8)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 8) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 9)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 9) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 10)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 11)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 11) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 12)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 12) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 13)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 13) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 14)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 14) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 15)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (6) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 0)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 3)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 3) with dispatcher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 4)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 6)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 7)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 7) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 9)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 9) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 12)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 12) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 15)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 3)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 4)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 12)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 12) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 15)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 4)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 15)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (0, 0, 15)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\statsmodels\\nonparametric\\kernels.py:64: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 0)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 0) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 1)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 1) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 2)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 2) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 3)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 3) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 4)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 4) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 5)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 5) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 6)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 6) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 7)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (12) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 7) with dispatcher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 0)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 0) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 2)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 2) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 4)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 4) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 7)\n",
      "C:\\Users\\Philipp\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 7) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 2)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 2) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 7)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 7) with dispatcher\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: start processing job (1, 0, 2)\n",
      "INFO:hpbandster.run_0.worker.DESKTOP-KV1H67P.7872:WORKER: registered result for job (1, 0, 2) with dispatcher\n",
      "INFO:hpbandster:DISPATCHER: Dispatcher shutting down\n",
      "INFO:hpbandster:DISPATCHER: shut down complete\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import ConfigSpace.read_and_write.json as json_writer\n",
    "import hpbandster.core.nameserver as hpns\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "\n",
    "# Create a configuration space\n",
    "config_space = sample_configspace()\n",
    "\n",
    "# Write the ConfigSpace for later use to file\n",
    "with open('example1_configspace.json', 'w') as fh:\n",
    "    fh.write(json_writer.write(config_space))\n",
    "\n",
    "# Every run has to have a unique (at runtime) id.\n",
    "run_id = '0'\n",
    "\n",
    "# Step 1: Set up the nameserver\n",
    "NS = hpns.NameServer(run_id=run_id, host='localhost', port=0)\n",
    "ns_host, ns_port = NS.start()\n",
    "\n",
    "# Step 2: Connect the worker with the nameserver\n",
    "w = MyWorker(nameserver=ns_host,\n",
    "             nameserver_port=ns_port,\n",
    "             run_id=run_id,  # unique Hyperband run id (same as nameserver's)\n",
    "            )\n",
    "w.run(background=True)\n",
    "\n",
    "# Step 3: Create the optimizer object and run it\n",
    "bohb = BOHB(  configspace = config_space,\n",
    "              run_id = run_id,  # same as nameserver's\n",
    "              eta=2, min_budget=5, max_budget=100,  # Hyperband parameters\n",
    "              nameserver=ns_host,\n",
    "              nameserver_port = ns_port,\n",
    "              ping_interval=3600,  # how often master pings for workers (in seconds)\n",
    "           )\n",
    "\n",
    "# Then start the optimizer. The n_iterations parameter specifies\n",
    "# the number of iterations to be performed in this run\n",
    "res = bohb.run(n_iterations=2)\n",
    "\n",
    "# After the optimizer run, we shutdown the master.\n",
    "bohb.shutdown(shutdown_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 24 unique configurations where sampled.\n",
      "A total of 46 runs where executed.\n",
      "Best configuration found: {'activation': 'tanh', 'learning_rate_init': 0.004206450139653074, 'solver': 'adam', 'beta_1': 0.21261583890950886, 'beta_2': 0.056408063517268014}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4 Plotting the results\n",
    "\n",
    "# The returned result object holds informations about the optimization run\n",
    "# like the incumbent (=best) configuration.\n",
    "id2config = res.get_id2config_mapping()\n",
    "print('A total of %i unique configurations where sampled.' % len(id2config.keys()))\n",
    "print('A total of %i runs where executed.' % len(res.get_all_runs()))\n",
    "print('Best configuration found: {}'.format(id2config[res.get_incumbent_id()]['config']))\n",
    "\n",
    "# The incumbent trajectory is a dictionary with all the configuration IDs, the times the runs\n",
    "# finished, their respective budgets, and corresponding losses.\n",
    "# It's used to do meaningful plots of the optimization process.\n",
    "incumbent_trajectory = res.get_incumbent_trajectory()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(incumbent_trajectory['times_finished'], incumbent_trajectory['losses'])\n",
    "plt.xlabel('wall clock time [s]')\n",
    "plt.ylabel('incumbent loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the results in CAVE\n",
    "\n",
    "### 2.1) Magic Cavtivity \n",
    " HIER kann man Cave einbinden! :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
